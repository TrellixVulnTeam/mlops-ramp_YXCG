{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. SageMaker Training with Experiments and Processing For AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 작업의 실행 노트북 개요\n",
    "\n",
    "- SageMaker Training에 SageMaker 실험을 추가하여 여러 실험의 결과를 비교할 수 있습니다.\n",
    "    - [작업 실행 시 필요 라이브러리 import](#작업-실행-시-필요-라이브러리-import)\n",
    "    - [SageMaker 세션과 Role, 사용 버킷 정의](#SageMaker-세션과-Role,-사용-버킷-정의)\n",
    "    - [하이퍼파라미터 정의](#하이퍼파라미터-정의)\n",
    "    - [학습 실행 작업 정의](#학습-실행-작업-정의)\n",
    "        - 학습 코드 명\n",
    "        - 학습 코드 폴더 명\n",
    "        - 학습 코드가 사용한 Framework 종류, 버전 등\n",
    "        - 학습 인스턴스 타입과 개수\n",
    "        - SageMaker 세션\n",
    "        - 학습 작업 하이퍼파라미터 정의\n",
    "        - 학습 작업 산출물 관련 S3 버킷 설정 등\n",
    "    - [학습 데이터셋 지정](#학습-데이터셋-지정)\n",
    "        - 학습에 사용하는 데이터셋의 S3 URI 지정\n",
    "    - [SageMaker 실험 설정](#SageMaker-실험-설정)\n",
    "    - [학습 실행](#학습-실행)\n",
    "    - [데이터 세트 설명](#데이터-세트-설명)\n",
    "    - [실험 결과 보기](#실험-결과-보기)\n",
    "    - [Evaluation 하기](#Evaluation-하기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 작업 실행 시 필요 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.7/site-packages (0.1.35)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.22.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.0.0)\n",
      "Requirement already satisfied: botocore<1.26.0,>=1.25.2 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.25.2)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.26.0,>=1.25.2->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.26.0,>=1.25.2->boto3>=1.16.27->sagemaker-experiments) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.26.0,>=1.25.2->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ag_model import (\n",
    "    AutoGluonTraining,\n",
    "    AutoGluonInferenceModel,\n",
    "    AutoGluonTabularPredictor,\n",
    "    AutoGluonFramework\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker 세션과 Role, 사용 버킷 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session._region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "code_location = f's3://{bucket}/autogluon/code'\n",
    "output_path = f's3://{bucket}/autogluon/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "       \"config_name\" : \"config-med.yaml\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터셋 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../data/dataset/test.csv to s3://sagemaker-us-east-1-238312515155/autogluon/dataset/test.csv\n",
      "upload: ../data/dataset/test_no_header.csv to s3://sagemaker-us-east-1-238312515155/autogluon/dataset/test_no_header.csv\n",
      "upload: ../data/dataset/.ipynb_checkpoints/train-checkpoint.csv to s3://sagemaker-us-east-1-238312515155/autogluon/dataset/.ipynb_checkpoints/train-checkpoint.csv\n",
      "upload: ../data/dataset/train.csv to s3://sagemaker-us-east-1-238312515155/autogluon/dataset/train.csv\n",
      "upload: config/config/.ipynb_checkpoints/config-full-checkpoint.yaml to s3://sagemaker-us-east-1-238312515155/autogluon/config/config/.ipynb_checkpoints/config-full-checkpoint.yaml\n",
      "upload: config/config/.ipynb_checkpoints/config-med-checkpoint.yaml to s3://sagemaker-us-east-1-238312515155/autogluon/config/config/.ipynb_checkpoints/config-med-checkpoint.yaml\n",
      "upload: config/config/config-med.yaml to s3://sagemaker-us-east-1-238312515155/autogluon/config/config/config-med.yaml\n",
      "upload: config/config/config-full.yaml to s3://sagemaker-us-east-1-238312515155/autogluon/config/config/config-full.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-238312515155/autogluon/dataset'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path=f's3://{bucket}/autogluon/dataset'\n",
    "config_path = f's3://{bucket}/autogluon/config'\n",
    "!aws s3 sync ../data/dataset/ $data_path\n",
    "!aws s3 sync ./config/ $config_path\n",
    "\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 실행 작업 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.m5.large\"\n",
    "# instance_type = 'local'\n",
    "max_run = 1*60*60\n",
    "\n",
    "use_spot_instances = False\n",
    "if use_spot_instances:\n",
    "    max_wait = 1*60*60\n",
    "else:\n",
    "    max_wait = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if instance_type == 'local':\n",
    "    from sagemaker.local import LocalSession\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    local_data_path = \"file://\" + os.getcwd().replace('/lab_1_training', '') + \"/data/dataset\"\n",
    "    \n",
    "    data_channels = {\n",
    "        \"inputdata\": local_data_path, \n",
    "        \"config\" : \"file://\" + os.getcwd() + '/config'\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    sess = boto3.Session()\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    sm = sess.client('sagemaker')\n",
    "    \n",
    "    data_channels = {\n",
    "        \"inputdata\": data_path, \n",
    "        \"config\" : config_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_estimator = AutoGluonTraining(\n",
    "    entry_point=\"autogluon_starter_script.py\",\n",
    "    source_dir=os.getcwd() + \"/src\",\n",
    "    role=role,\n",
    "    # region=region,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    framework_version=\"0.4\",\n",
    "    py_version=\"py38\",\n",
    "    max_run=max_run,\n",
    "    use_spot_instances=use_spot_instances,  # spot instance 활용\n",
    "    max_wait=max_wait,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker 실험 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name='autogluon-poc-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name):\n",
    "    try:\n",
    "        sm_experiment = Experiment.load(experiment_name)\n",
    "    except:\n",
    "        sm_experiment = Experiment.create(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial(experiment_name):\n",
    "    create_date = strftime(\"%m%d-%H%M%s\")\n",
    "\n",
    "    sm_trial = Trial.create(trial_name=f'{experiment_name}-{create_date}',\n",
    "                            experiment_name=experiment_name)\n",
    "\n",
    "    job_name = f'{sm_trial.trial_name}'\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputdata': 's3://sagemaker-us-east-1-238312515155/autogluon/dataset',\n",
       " 'config': 's3://sagemaker-us-east-1-238312515155/autogluon/config'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: autogluon-poc-1-0722-14421658500967\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name)\n",
    "\n",
    "ag_estimator.fit(inputs = data_channels,\n",
    "                  job_name = job_name,\n",
    "                  experiment_config={\n",
    "                      'TrialName': job_name,\n",
    "                      'TrialComponentDisplayName': job_name,\n",
    "                  },\n",
    "                  wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-22 14:42:48 Starting - Starting the training job...\n",
      "2022-07-22 14:43:12 Starting - Preparing the instances for trainingProfilerReport-1658500968: InProgress\n",
      ".........\n",
      "2022-07-22 14:44:32 Downloading - Downloading input data...\n",
      "2022-07-22 14:45:13 Training - Downloading the training image.........\n",
      "2022-07-22 14:46:40 Training - Training image download completed. Training in progress..\u001b[34m2022-07-22 14:46:42,551 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2022-07-22 14:46:42,554 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-22 14:46:42,568 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"config_name\":\"config-med.yaml\"}', 'SM_USER_ENTRY_POINT': 'autogluon_starter_script.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"inputdata\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"config\",\"inputdata\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'autogluon_starter_script', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '2', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-238312515155/autogluon/code/autogluon-poc-1-0722-14421658500967/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"inputdata\":\"/opt/ml/input/data/inputdata\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config_name\":\"config-med.yaml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"inputdata\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"autogluon-poc-1-0722-14421658500967\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-238312515155/autogluon/code/autogluon-poc-1-0722-14421658500967/source/sourcedir.tar.gz\",\"module_name\":\"autogluon_starter_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"autogluon_starter_script.py\"}', 'SM_USER_ARGS': '[\"--config_name\",\"config-med.yaml\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_CONFIG': '/opt/ml/input/data/config', 'SM_CHANNEL_INPUTDATA': '/opt/ml/input/data/inputdata', 'SM_HP_CONFIG_NAME': 'config-med.yaml'}\u001b[0m\n",
      "\u001b[34m2022-07-22 14:46:43,181 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-22 14:46:43,196 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-22 14:46:43,213 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-22 14:46:43,227 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"inputdata\": \"/opt/ml/input/data/inputdata\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config_name\": \"config-med.yaml\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"inputdata\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"autogluon-poc-1-0722-14421658500967\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-238312515155/autogluon/code/autogluon-poc-1-0722-14421658500967/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"autogluon_starter_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"autogluon_starter_script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config_name\":\"config-med.yaml\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=autogluon_starter_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"inputdata\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"config\",\"inputdata\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=autogluon_starter_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-238312515155/autogluon/code/autogluon-poc-1-0722-14421658500967/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"inputdata\":\"/opt/ml/input/data/inputdata\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config_name\":\"config-med.yaml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"inputdata\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"autogluon-poc-1-0722-14421658500967\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-238312515155/autogluon/code/autogluon-poc-1-0722-14421658500967/source/sourcedir.tar.gz\",\"module_name\":\"autogluon_starter_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"autogluon_starter_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config_name\",\"config-med.yaml\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CONFIG=/opt/ml/input/data/config\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_INPUTDATA=/opt/ml/input/data/inputdata\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG_NAME=config-med.yaml\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 autogluon_starter_script.py --config_name config-med.yaml\u001b[0m\n",
      "\u001b[34mStarting AG\u001b[0m\n",
      "\u001b[34margs.ag_config : /opt/ml/input/data/config/config-med.yaml\u001b[0m\n",
      "\u001b[34mWarning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\u001b[0m\n",
      "\u001b[34mPreset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\u001b[0m\n",
      "\u001b[34mPresets specified: ['medium_quality_faster_train']\u001b[0m\n",
      "\u001b[34mBeginning AutoGluon training ...\u001b[0m\n",
      "\u001b[34mAutoGluon will save models to \"/opt/ml/model/\"\u001b[0m\n",
      "\u001b[34mAutoGluon Version:  0.4.2\u001b[0m\n",
      "\u001b[34mPython Version:     3.8.10\u001b[0m\n",
      "\u001b[34mOperating System:   Linux\u001b[0m\n",
      "\u001b[34mTrain Data Rows:    4500\u001b[0m\n",
      "\u001b[34mTrain Data Columns: 58\u001b[0m\n",
      "\u001b[34mLabel Column: fraud\u001b[0m\n",
      "\u001b[34mPreprocessing data ...\u001b[0m\n",
      "\u001b[34mAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\u001b[0m\n",
      "\u001b[34m#0112 unique label values:  [0, 1]\u001b[0m\n",
      "\u001b[34m#011If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\u001b[0m\n",
      "\u001b[34mSelected class <--> label mapping:  class 1 = 1, class 0 = 0\u001b[0m\n",
      "\u001b[34mUsing Feature Generators to preprocess the data ...\u001b[0m\n",
      "\u001b[34mFitting AutoMLPipelineFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Available Memory:                    6855.27 MB\u001b[0m\n",
      "\u001b[34m#011Train Data (Original)  Memory Usage: 2.09 MB (0.0% of available memory)\u001b[0m\n",
      "\u001b[34m#011Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\u001b[0m\n",
      "\u001b[34m#011Stage 1 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting AsTypeFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011#011#011Note: Converting 40 features to boolean dtype as they only contain 2 unique values.\u001b[0m\n",
      "\u001b[34m#011Stage 2 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting FillNaFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 3 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting IdentityFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 4 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting DropUniqueFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Types of features in original data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('float', []) :  2 | ['vehicle_claim', 'total_claim_amount']\u001b[0m\n",
      "\u001b[34m#011#011('int', [])   : 56 | ['customer_age', 'months_as_customer', 'num_claims_past_year', 'num_insurers_past_5_years', 'policy_deductable', ...]\u001b[0m\n",
      "\u001b[34m#011Types of features in processed data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('float', [])     :  2 | ['vehicle_claim', 'total_claim_amount']\u001b[0m\n",
      "\u001b[34m#011#011('int', [])       : 16 | ['customer_age', 'months_as_customer', 'num_claims_past_year', 'num_insurers_past_5_years', 'policy_deductable', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', ['bool']) : 40 | ['policy_state_AZ', 'policy_state_CA', 'policy_state_ID', 'policy_state_NV', 'policy_state_OR', ...]\u001b[0m\n",
      "\u001b[34m#0110.1s = Fit runtime\u001b[0m\n",
      "\u001b[34m#01158 features in original data used to generate 58 features in processed data.\u001b[0m\n",
      "\u001b[34m#011Train Data (Processed) Memory Usage: 0.83 MB (0.0% of available memory)\u001b[0m\n",
      "\u001b[34mData preprocessing and feature engineering runtime = 0.16s ...\u001b[0m\n",
      "\u001b[34mAutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\u001b[0m\n",
      "\u001b[34m#011This metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\u001b[0m\n",
      "\u001b[34m#011To change this, specify the eval_metric parameter of Predictor()\u001b[0m\n",
      "\u001b[34mFitting 13 L1 models ...\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsUnif_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.5437#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.74s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsDist_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.5463#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.75s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMXT_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m#0110.7506#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0112.44s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.04s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBM_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m#0110.7474#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0113.41s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.03s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestGini_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.751#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0112.77s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.42s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestEntr_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.7426#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0112.54s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.4s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: CatBoost_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m#0110.7805#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0114.61s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.02s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesGini_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.6998#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0111.67s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.42s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesEntr_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.7192#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0111.62s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.41s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetFastAI_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m#0110.6005#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0119.21s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.21s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: XGBoost_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m#0110.7809#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0112.17s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.05s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetTorch_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m#0110.7585#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0119.54s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.14s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMLarge_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#011Fitting 2 child models (S1F1 - S1F2) | Fitting with ParallelLocalFoldFittingStrategy\u001b[0m\n",
      "\u001b[34m#0110.6736#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0114.35s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.02s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: WeightedEnsemble_L2 ...\u001b[0m\n",
      "\u001b[34m#0110.8016#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0115.11s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mAutoGluon training complete, total runtime = 83.3s ... Best model: \"WeightedEnsemble_L2\"\u001b[0m\n",
      "\u001b[34mTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/ml/model/\")\u001b[0m\n",
      "\u001b[34mLoaded data from: /opt/ml/input/data/inputdata/test.csv | Columns = 59 / 59 | Rows = 500 -> 500\u001b[0m\n",
      "\u001b[34m                      model  score_test  score_val  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\u001b[0m\n",
      "\u001b[34m0   RandomForestGini_BAG_L1    0.774983   0.751003        0.128776       0.424637   2.770441                 0.128776                0.424637           2.770441            1       True          5\u001b[0m\n",
      "\u001b[34m1       WeightedEnsemble_L2    0.759588   0.801622        0.424977       1.423651  26.638335                 0.005312                0.003590           5.110508            2       True         14\u001b[0m\n",
      "\u001b[34m2           CatBoost_BAG_L1    0.755464   0.780512        0.019786       0.023027   4.608847                 0.019786                0.023027           4.608847            1       True          7\u001b[0m\n",
      "\u001b[34m3            XGBoost_BAG_L1    0.752027   0.780921        0.020550       0.047167   2.165444                 0.020550                0.047167           2.165444            1       True         11\u001b[0m\n",
      "\u001b[34m4   RandomForestEntr_BAG_L1    0.743368   0.742626        0.139475       0.398807   2.543680                 0.139475                0.398807           2.543680            1       True          6\u001b[0m\n",
      "\u001b[34m5           LightGBM_BAG_L1    0.741306   0.747435        0.029565       0.034163   3.411407                 0.029565                0.034163           3.411407            1       True          4\u001b[0m\n",
      "\u001b[34m6         LightGBMXT_BAG_L1    0.734021   0.750568        0.031914       0.036327   2.436882                 0.031914                0.036327           2.436882            1       True          3\u001b[0m\n",
      "\u001b[34m7      LightGBMLarge_BAG_L1    0.732234   0.673617        0.046317       0.021901   4.353707                 0.046317                0.021901           4.353707            1       True         13\u001b[0m\n",
      "\u001b[34m8     NeuralNetTorch_BAG_L1    0.727148   0.758527        0.100520       0.140327   9.537485                 0.100520                0.140327           9.537485            1       True         12\u001b[0m\n",
      "\u001b[34m9     ExtraTreesGini_BAG_L1    0.685292   0.699760        0.168932       0.420006   1.669844                 0.168932                0.420006           1.669844            1       True          8\u001b[0m\n",
      "\u001b[34m10    ExtraTreesEntr_BAG_L1    0.679038   0.719198        0.147285       0.411182   1.624277                 0.147285                0.411182           1.624277            1       True          9\u001b[0m\n",
      "\u001b[34m11   NeuralNetFastAI_BAG_L1    0.612509   0.600465        1.071970       0.206643   9.212100                 1.071970                0.206643           9.212100            1       True         10\u001b[0m\n",
      "\u001b[34m12    KNeighborsDist_BAG_L1    0.490034   0.546268        0.118119       0.748576   0.008729                 0.118119                0.748576           0.008729            1       True          2\u001b[0m\n",
      "\u001b[34m13    KNeighborsUnif_BAG_L1    0.488385   0.543672        0.128129       0.737040   0.012371                 0.128129                0.737040           0.012371            1       True          1\u001b[0m\n",
      "\u001b[34mComputing feature importance via permutation shuffling for 58 features using 500 rows with 5 shuffle sets...\u001b[0m\n",
      "\u001b[34m#011150.71s#011= Expected runtime (30.14s per shuffle set)\u001b[0m\n",
      "\u001b[34m#01142.04s#011= Actual runtime (Completed 5 of 5 shuffle sets)\u001b[0m\n",
      "\u001b[34m2022-07-22 14:48:58,392 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-07-22 14:49:22 Uploading - Uploading generated training model\n",
      "2022-07-22 14:49:22 Completed - Training job completed\n",
      "Training seconds: 298\n",
      "Billable seconds: 298\n"
     ]
    }
   ],
   "source": [
    "ag_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  실험 결과 보기\n",
    "위의 실험한 결과를 확인 합니다.\n",
    "- 각각의 훈련잡의 시도에 대한 훈련 사용 데이터, 모델 입력 하이퍼 파라미터, 모델 평가 지표, 모델 아티펙트 결과 위치 등의 확인이 가능합니다.\n",
    "- **아래의 모든 내용은 SageMaker Studio 를 통해서 직관적으로 확인이 가능합니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-238312515155/autogluon/output/autogluon-poc-1-0722-14421658500967/output/model.tar.gz to autogluon/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./autogluon/\n",
    "!mkdir -p ./autogluon/result\n",
    "!aws s3 cp {ag_estimator.model_data} ./autogluon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 11118023 Jul 22 14:49 ./autogluon/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -alF ./autogluon/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf ./autogluon/model.tar.gz -C ./autogluon/result/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\"\n",
    "# instance_type = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if instance_type == 'local':\n",
    "    from sagemaker.local import LocalSession\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "else:\n",
    "    sess = boto3.Session()\n",
    "    sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoGluonInferenceModel(\n",
    "    source_dir=os.getcwd() + \"/src\",\n",
    "    entry_point=\"autogluon_serve.py\",\n",
    "    model_data=ag_estimator.model_data,\n",
    "    instance_type=instance_type,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    # region=region,\n",
    "    framework_version=\"0.4\",\n",
    "    py_version=\"py38\",\n",
    "    predictor_cls=AutoGluonTabularPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: autogluon-inference-2022-07-22-14-50-04-093\n",
      "INFO:sagemaker:Creating endpoint-config with name autogluon-inference-2022-07-22-14-50-04-721\n",
      "INFO:sagemaker:Creating endpoint with name autogluon-inference-2022-07-22-14-50-04-721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1, serializer=CSVSerializer(), instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on unlabeled test data\n",
    "\n",
    "Remove target variable (`fraud`) from the data and get predictions for a sample of 100 rows using the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "data = df.drop(columns=\"fraud\")[:100].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.predict(data)\n",
    "pred_df = pd.DataFrame(json.loads(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['fraud'].reset_index(drop=True, inplace=True)\n",
    "df[\"fraud\"][:len(pred_df)].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preds  actual\n",
       "0      0       0\n",
       "1      0       0\n",
       "2      0       0\n",
       "3      0       0\n",
       "4      0       0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.DataFrame({\"preds\": pred_df['fraud'], \"actual\": df[\"fraud\"][: len(pred_df)]})\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/100 are correct\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(p.preds==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
     ]
    }
   ],
   "source": [
    "!predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Batch Transform\n",
    "\n",
    "학습된 모델을 호스트된 엔드포인트에 배포하는 것은 출시 이후 SageMaker에서 사용할 수 있으며 웹 사이트나 모바일 앱과 같은 서비스에 실시간 예측을 제공하는 좋은 방법입니다. 그러나 지연 시간을 최소화하는 것이 문제가 되지 않는 대규모 데이터 세트에서 학습된 모델에서 예측을 생성하는 것이 목표라면 배치 변환 기능이 더 쉽고, 더 확장 가능하며, 더 적절할 수 있다.\n",
    "\n",
    "[Read more about Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoGluonInferenceModel(\n",
    "#     source_dir=os.getcwd() + \"/src\",\n",
    "#     entry_point=\"autogluon_serve.py\",\n",
    "#     model_data=ag_estimator.model_data,\n",
    "#     instance_type=instance_type,\n",
    "#     role=role,\n",
    "#     sagemaker_session=sagemaker_session,\n",
    "#     region=region,\n",
    "#     framework_version=\"0.4\",\n",
    "#     py_version=\"py38\",    \n",
    "#     predictor_cls=AutoGluonTabularPredictor,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: autogluon-inference-2022-07-22-14-53-30-823\n"
     ]
    }
   ],
   "source": [
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=6,\n",
    "    max_concurrent_transforms=1,\n",
    "    output_path=output_path,\n",
    "    accept=\"application/json\",\n",
    "    assemble_with=\"Line\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f\"../data/dataset/test.csv\")[:100].to_csv(\"../data/dataset/test_no_header.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-238312515155/sagemaker-us-east-1-238312515155/autogluon/dataset/test_no_header.csv'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = transformer.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"../data/dataset\", \"test_no_header.csv\"), key_prefix=f\"{bucket}/autogluon/dataset\"\n",
    ")\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: autogluon-inference-2022-07-22-14-53-31-885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[34mWarning: MMS is using non-default JVM parameters: -XX:-UseContainerSupport\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,122 [INFO ] main com.amazonaws.ml.mms.ModelServer - \u001b[0m\n",
      "\u001b[34mMMS Home: /usr/local/lib/python3.8/dist-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 8\u001b[0m\n",
      "\u001b[34mMax heap size: 7045 M\u001b[0m\n",
      "\u001b[34mPython executable: /usr/bin/python3\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-mms.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/mms/models\u001b[0m\n",
      "\u001b[34mInitial Models: ALL\u001b[0m\n",
      "\u001b[34mLog dir: null\u001b[0m\n",
      "\u001b[34mMetrics dir: null\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 8\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPreload model: false\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,177 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,243 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /home/model-server/tmp/.mms.sock.9000 --handler sagemaker_mxnet_serving_container.handler_service --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /home/model-server/tmp\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 83\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.8.10\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,245 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,250 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,260 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,261 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,261 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,260 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,321 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,322 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,325 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,326 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,327 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,329 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,330 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,338 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,338 [WARN ] pool-3-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,346 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,076 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000003-a1f26b4f9a6b05ab-9acf7d07\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,108 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2691\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,110 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-3\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,272 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000001-67afab4f9a6b05ab-7ab465b5\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,273 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2787\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,275 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,361 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000006-f7d31b4f9a6b05ab-edaeb493\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,362 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2876\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,362 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-4\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,381 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000008-d0085b4f9a6b05ac-20428e6c\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,382 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2899\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,382 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-7\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,411 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000000-52d7ab4f9a6b05ab-3a2cd950\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,412 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2926\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,412 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-8\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,430 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000005-e3111b4f9a6b05ab-6f9d20c1\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,430 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2941\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,431 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-6\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,437 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000004-37c61b4f9a6b05ab-69481517\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,438 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2948\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,438 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,447 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000002-296fab4f9a6b05ab-4331809d\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,448 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2962\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,448 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-5\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:49,242 [INFO ] pool-2-thread-10 ACCESS_LOG - /169.254.255.130:59040 \"GET /ping HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:49,255 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:59044 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\n",
      "\u001b[34m2022-07-22T14:58:50,530 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:50,531 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:59048 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:50,530 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:50,531 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:59048 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[32m2022-07-22T14:58:49.260:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mWarning: MMS is using non-default JVM parameters: -XX:-UseContainerSupport\u001b[0m\n",
      "\u001b[35mWarning: MMS is using non-default JVM parameters: -XX:-UseContainerSupport\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,122 [INFO ] main com.amazonaws.ml.mms.ModelServer - \u001b[0m\n",
      "\u001b[34mMMS Home: /usr/local/lib/python3.8/dist-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 8\u001b[0m\n",
      "\u001b[34mMax heap size: 7045 M\u001b[0m\n",
      "\u001b[34mPython executable: /usr/bin/python3\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-mms.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/mms/models\u001b[0m\n",
      "\u001b[34mInitial Models: ALL\u001b[0m\n",
      "\u001b[34mLog dir: null\u001b[0m\n",
      "\u001b[34mMetrics dir: null\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 8\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPreload model: false\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,177 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,243 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /home/model-server/tmp/.mms.sock.9000 --handler sagemaker_mxnet_serving_container.handler_service --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /home/model-server/tmp\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,122 [INFO ] main com.amazonaws.ml.mms.ModelServer - \u001b[0m\n",
      "\u001b[35mMMS Home: /usr/local/lib/python3.8/dist-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 8\u001b[0m\n",
      "\u001b[35mMax heap size: 7045 M\u001b[0m\n",
      "\u001b[35mPython executable: /usr/bin/python3\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-mms.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/mms/models\u001b[0m\n",
      "\u001b[35mInitial Models: ALL\u001b[0m\n",
      "\u001b[35mLog dir: null\u001b[0m\n",
      "\u001b[35mMetrics dir: null\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 8\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPreload model: false\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,177 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,243 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /home/model-server/tmp/.mms.sock.9000 --handler sagemaker_mxnet_serving_container.handler_service --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /home/model-server/tmp\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 83\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.8.10\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,245 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,250 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,260 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,261 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,261 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,260 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,321 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,322 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,325 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,326 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,327 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,329 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,330 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,338 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,338 [WARN ] pool-3-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:44,346 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 83\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,244 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.8.10\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,245 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,250 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,260 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,261 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,261 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,260 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,259 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,321 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,322 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,325 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,326 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,327 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,329 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,330 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,338 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,338 [WARN ] pool-3-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:44,346 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,076 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000003-a1f26b4f9a6b05ab-9acf7d07\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,108 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2691\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,110 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-3\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,272 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000001-67afab4f9a6b05ab-7ab465b5\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,273 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2787\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,275 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,361 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000006-f7d31b4f9a6b05ab-edaeb493\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,362 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2876\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,362 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-4\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,381 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000008-d0085b4f9a6b05ac-20428e6c\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,382 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2899\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,382 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-7\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,411 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000000-52d7ab4f9a6b05ab-3a2cd950\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,412 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2926\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,412 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-8\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,430 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000005-e3111b4f9a6b05ab-6f9d20c1\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,430 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2941\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,431 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-6\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,437 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000004-37c61b4f9a6b05ab-69481517\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,438 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2948\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,076 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000003-a1f26b4f9a6b05ab-9acf7d07\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,108 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2691\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,110 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-3\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,272 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000001-67afab4f9a6b05ab-7ab465b5\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,273 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2787\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,275 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,361 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000006-f7d31b4f9a6b05ab-edaeb493\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,362 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2876\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,362 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-4\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,381 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000008-d0085b4f9a6b05ac-20428e6c\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,382 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2899\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,382 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-7\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,411 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000000-52d7ab4f9a6b05ab-3a2cd950\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,412 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2926\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,412 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-8\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,430 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000005-e3111b4f9a6b05ab-6f9d20c1\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,430 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2941\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,431 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-6\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,437 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000004-37c61b4f9a6b05ab-69481517\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,438 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2948\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,438 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,447 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000002-296fab4f9a6b05ab-4331809d\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,448 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2962\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:47,448 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-5\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,438 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,447 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000002-296fab4f9a6b05ab-4331809d\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,448 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2962\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:47,448 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-5\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:49,242 [INFO ] pool-2-thread-10 ACCESS_LOG - /169.254.255.130:59040 \"GET /ping HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:49,255 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:59044 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:49,242 [INFO ] pool-2-thread-10 ACCESS_LOG - /169.254.255.130:59040 \"GET /ping HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:49,255 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:59044 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:50,530 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[34m2022-07-22T14:58:50,531 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:59048 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:50,530 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[35m2022-07-22T14:58:50,531 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:59048 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[32m2022-07-22T14:58:49.260:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    test_input,\n",
    "    input_filter=\"$[1:]\",  # filter-out target variable\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "    output_filter=\"$['fraud']\",  # keep only prediction class in the output\n",
    ")\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch transform 결과를 다운로드 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./autogluon_batch_result\n",
    "!mkdir ./autogluon_batch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-238312515155/autogluon/output'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-238312515155/autogluon/output/test_no_header.csv.out to autogluon_batch_result/test_no_header.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {transformer.output_path}/test_no_header.csv.out ./autogluon_batch_result/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preds  actual\n",
       "0      0       0\n",
       "1      0       0\n",
       "2      0       0\n",
       "3      0       0\n",
       "4      0       0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.concat(\n",
    "    [\n",
    "        pd.read_json(\"./autogluon_batch_result/test_no_header.csv.out\", orient=\"index\")\n",
    "        .sort_index()\n",
    "        .rename(columns={0: \"preds\"}),\n",
    "        pd.read_csv(\"../data/dataset/test.csv\")[[\"fraud\"]].iloc[:100].rename(columns={\"fraud\": \"actual\"}),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/100 are correct\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(p.preds==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Processing Evaluation 하기\n",
    "SageMaker Processing을 이용하여 Evalution을 수행하는 코드를 동작할 수 있습니다. MLOps에서 Processing을 적용하면 전처리, Evaluation 등을 serverless로 동작할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import FrameworkProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.estimator import Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count = 1\n",
    "instance_type = \"ml.m5.large\"\n",
    "# instance_type = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/autogluon-training:0.4-cpu-py38'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "image_uri = image_uris.retrieve(\n",
    "    \"autogluon\",\n",
    "    region=region,\n",
    "    version=\"0.4\",\n",
    "    py_version=\"py38\",\n",
    "    image_scope=\"training\",\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "image_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_eval = FrameworkProcessor(\n",
    "    AutoGluonFramework,\n",
    "    framework_version=\"0.4\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    image_uri=image_uri,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_outputpath = f's3://{bucket}/autogluon/processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir='src'\n",
    "\n",
    "if instance_type == 'local':\n",
    "    from sagemaker.local import LocalSession\n",
    "    from pathlib import Path\n",
    "    \n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    source_dir = f'{Path.cwd()}/src'\n",
    "    s3_test_path=f'../data/dataset/test.csv'\n",
    "else:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    s3_test_path = data_path + '/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.processing:Uploaded src to s3://sagemaker-us-east-1-238312515155/autogluon-poc-1-0722-14591658501959/source/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sagemaker-us-east-1-238312515155/autogluon-poc-1-0722-14591658501959/source/runproc.sh\n",
      "INFO:sagemaker:Creating processing-job with name autogluon-poc-1-0722-14591658501959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  autogluon-poc-1-0722-14591658501959\n",
      "Inputs:  [{'InputName': 'test_data', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/autogluon/dataset/test.csv', 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'model_weight', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/autogluon/output/autogluon-poc-1-0722-14421658500967/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/autogluon-poc-1-0722-14591658501959/source/sourcedir.tar.gz', 'LocalPath': '/opt/ml/processing/input/code/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'entrypoint', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/autogluon-poc-1-0722-14591658501959/source/runproc.sh', 'LocalPath': '/opt/ml/processing/input/entrypoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'evaluation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/autogluon/processing/autogluon-poc-1-0722-14591658501959', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name)\n",
    "job_name = create_trial(experiment_name)\n",
    "\n",
    "script_eval.run(\n",
    "    code=\"autogluon_evaluation.py\",\n",
    "    source_dir=source_dir,\n",
    "    inputs=[ProcessingInput(source=s3_test_path, input_name=\"test_data\", destination=\"/opt/ml/processing/test\"),\n",
    "            ProcessingInput(source=ag_estimator.model_data, input_name=\"model_weight\", destination=\"/opt/ml/processing/model\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/output\", output_name='evaluation', destination=detect_outputpath + \"/\" + job_name),\n",
    "    ],\n",
    "    job_name=job_name,\n",
    "    experiment_config={\n",
    "        'TrialName': job_name,\n",
    "        'TrialComponentDisplayName': job_name,\n",
    "    },\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34m485/500 are correct\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "script_eval.latest_job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
