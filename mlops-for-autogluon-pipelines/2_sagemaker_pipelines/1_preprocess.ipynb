{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 2-1] SageMaker Pipelines 사용하기\n",
    "이 노트북에서는 아래와 같은 작업을 수행합니다.\n",
    "- 데이터 준비\n",
    "- Pipeline 정의\n",
    "- 데이터 전처리: Processing Step 이용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_prefix = 'autoglueon'\n",
    "s3_data_path = f's3://{bucket}/{pipeline_prefix}/raw'\n",
    "s3_config_path = f's3://{bucket}/{pipeline_prefix}/config'\n",
    "\n",
    "sm_dataset_path = '../data/raw'\n",
    "sm_claims_data_path = f'{sm_dataset_path}/claims.csv'\n",
    "sm_customers_data_path = f'{sm_dataset_path}/customers.csv'\n",
    "sm_config_path = f'../config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_data_path:  ../data/raw/claims.csv\n",
      "customer_data_path:  ../data/raw/customers.csv\n",
      "s3_data_path:  s3://sagemaker-ap-northeast-2-457597599702/autoglueon/raw\n"
     ]
    }
   ],
   "source": [
    "print(\"claim_data_path: \", sm_claims_data_path)\n",
    "print(\"customer_data_path: \", sm_customers_data_path)\n",
    "print(\"s3_data_path: \", s3_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claims data path in S3:  s3://sagemaker-ap-northeast-2-457597599702/autoglueon/raw/claims.csv\n",
      "customers data path in S3:  s3://sagemaker-ap-northeast-2-457597599702/autoglueon/raw/customers.csv\n",
      "config path in S3:  s3://sagemaker-ap-northeast-2-457597599702/autoglueon/config\n"
     ]
    }
   ],
   "source": [
    "s3_claims_data_path = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path = sm_claims_data_path, \n",
    "    desired_s3_uri = s3_data_path\n",
    ")\n",
    "print(\"claims data path in S3: \", s3_claims_data_path)\n",
    "\n",
    "s3_customers_data_path = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path = sm_customers_data_path, \n",
    "    desired_s3_uri = s3_data_path\n",
    ")\n",
    "print(\"customers data path in S3: \", s3_customers_data_path)\n",
    "\n",
    "\n",
    "s3_config_path = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path = sm_config_path, \n",
    "    desired_s3_uri = s3_config_path\n",
    ")\n",
    "print(\"config path in S3: \", s3_config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 전처리 스텝 개발"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from IPython.display import display as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_id</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>num_claims_past_year</th>\n",
       "      <th>num_insurers_past_5_years</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>policy_liability</th>\n",
       "      <th>customer_zip</th>\n",
       "      <th>customer_gender</th>\n",
       "      <th>customer_education</th>\n",
       "      <th>auto_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>25/50</td>\n",
       "      <td>99207</td>\n",
       "      <td>Unkown</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>2950</td>\n",
       "      <td>15/30</td>\n",
       "      <td>95632</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>15/30</td>\n",
       "      <td>93203</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>30/60</td>\n",
       "      <td>85208</td>\n",
       "      <td>Female</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>15/30</td>\n",
       "      <td>91792</td>\n",
       "      <td>Female</td>\n",
       "      <td>High School</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policy_id  customer_age  months_as_customer  num_claims_past_year  \\\n",
       "0          1            54                  94                     0   \n",
       "1          2            41                 165                     0   \n",
       "2          3            57                 155                     0   \n",
       "3          4            39                  80                     0   \n",
       "4          5            39                  60                     0   \n",
       "\n",
       "   num_insurers_past_5_years policy_state  policy_deductable  \\\n",
       "0                          1           WA                750   \n",
       "1                          1           CA                750   \n",
       "2                          1           CA                750   \n",
       "3                          1           AZ                750   \n",
       "4                          1           CA                750   \n",
       "\n",
       "   policy_annual_premium policy_liability  customer_zip customer_gender  \\\n",
       "0                   3000            25/50         99207          Unkown   \n",
       "1                   2950            15/30         95632            Male   \n",
       "2                   3000            15/30         93203          Female   \n",
       "3                   3000            30/60         85208          Female   \n",
       "4                   3000            15/30         91792          Female   \n",
       "\n",
       "  customer_education  auto_year  \n",
       "0          Associate       2006  \n",
       "1           Bachelor       2012  \n",
       "2           Bachelor       2017  \n",
       "3    Advanced Degree       2020  \n",
       "4        High School       2018  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers = pd.read_csv(sm_customers_data_path)\n",
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_id</th>\n",
       "      <th>driver_relationship</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>collision_type</th>\n",
       "      <th>incident_severity</th>\n",
       "      <th>authorities_contacted</th>\n",
       "      <th>num_vehicles_involved</th>\n",
       "      <th>num_injuries</th>\n",
       "      <th>num_witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>incident_month</th>\n",
       "      <th>incident_day</th>\n",
       "      <th>incident_dow</th>\n",
       "      <th>incident_hour</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Front</td>\n",
       "      <td>Minor</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>71600</td>\n",
       "      <td>8913.668763</td>\n",
       "      <td>80513.668763</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Rear</td>\n",
       "      <td>Totaled</td>\n",
       "      <td>Police</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6400</td>\n",
       "      <td>19746.724395</td>\n",
       "      <td>26146.724395</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Front</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Police</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10400</td>\n",
       "      <td>11652.969918</td>\n",
       "      <td>22052.969918</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Child</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Side</td>\n",
       "      <td>Minor</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>104700</td>\n",
       "      <td>11260.930936</td>\n",
       "      <td>115960.930936</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Side</td>\n",
       "      <td>Major</td>\n",
       "      <td>Police</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>3400</td>\n",
       "      <td>27987.704652</td>\n",
       "      <td>31387.704652</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policy_id driver_relationship incident_type collision_type  \\\n",
       "0          1              Spouse     Collision          Front   \n",
       "1          2                Self     Collision           Rear   \n",
       "2          3                Self     Collision          Front   \n",
       "3          4               Child     Collision           Side   \n",
       "4          5                Self     Collision           Side   \n",
       "\n",
       "  incident_severity authorities_contacted  num_vehicles_involved  \\\n",
       "0             Minor                  None                      2   \n",
       "1           Totaled                Police                      3   \n",
       "2             Minor                Police                      2   \n",
       "3             Minor                  None                      2   \n",
       "4             Major                Police                      2   \n",
       "\n",
       "   num_injuries  num_witnesses police_report_available  injury_claim  \\\n",
       "0             0              0                      No         71600   \n",
       "1             4              0                     Yes          6400   \n",
       "2             0              1                     Yes         10400   \n",
       "3             0              0                      No        104700   \n",
       "4             1              0                      No          3400   \n",
       "\n",
       "   vehicle_claim  total_claim_amount  incident_month  incident_day  \\\n",
       "0    8913.668763        80513.668763               3            17   \n",
       "1   19746.724395        26146.724395              12            11   \n",
       "2   11652.969918        22052.969918              12            24   \n",
       "3   11260.930936       115960.930936              12            23   \n",
       "4   27987.704652        31387.704652               5             8   \n",
       "\n",
       "   incident_dow  incident_hour  fraud  \n",
       "0             6              8      0  \n",
       "1             2             11      0  \n",
       "2             1             14      0  \n",
       "3             0             19      0  \n",
       "4             2              8      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims = pd.read_csv(sm_claims_data_path)\n",
    "df_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/preprocess.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import subprocess, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import logging\n",
    "import logging.handlers\n",
    "\n",
    "def _get_logger():\n",
    "    '''\n",
    "    로깅을 위해 파이썬 로거를 사용\n",
    "    # https://stackoverflow.com/questions/17745914/python-logging-module-is-printing-lines-multiple-times\n",
    "    '''\n",
    "    loglevel = logging.DEBUG\n",
    "    l = logging.getLogger(__name__)\n",
    "    if not l.hasHandlers():\n",
    "        l.setLevel(loglevel)\n",
    "        logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))        \n",
    "        l.handler_set = True\n",
    "    return l  \n",
    "\n",
    "logger = _get_logger()\n",
    "\n",
    "\n",
    "def split_train_test(df, test_ratio=0.1):\n",
    "    '''\n",
    "    두 개의 데이터 세트로 분리\n",
    "    '''\n",
    "    total_rows = df.shape[0]\n",
    "    train_end = int(total_rows * (1 - test_ratio))\n",
    "    \n",
    "    train_df = df[0:train_end]\n",
    "    test_df = df[train_end:]\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def get_dataframe(base_preproc_input_dir, file_name_prefix ):    \n",
    "    '''\n",
    "    파일 이름이 들어가 있는 csv 파일을 모두 저장하여 데이터 프레임을 리턴\n",
    "    '''\n",
    "    \n",
    "    input_files = glob('{}/{}*.csv'.format(base_preproc_input_dir, file_name_prefix))\n",
    "    #claim_input_files = glob('{}/dataset*.csv'.format(base_preproc_input_dir))    \n",
    "    logger.info(f\"input_files: \\n {input_files}\")    \n",
    "    \n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(base_preproc_input_dir, \"train\"))\n",
    "        \n",
    "    raw_data = [ pd.read_csv(file, index_col=0) for file in input_files ]\n",
    "    df = pd.concat(raw_data)\n",
    "   \n",
    "    logger.info(f\"dataframe shape \\n {df.shape}\")    \n",
    "    logger.info(f\"dataset sample \\n {df.head(2)}\")        \n",
    "    #logger.info(f\"df columns \\n {df.columns}\")    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_type(raw, cols, type_target):\n",
    "    '''\n",
    "    해당 데이터 타입으로 변경\n",
    "    '''\n",
    "    df = raw.copy()\n",
    "    \n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(type_target)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "if __name__ =='__main__':\n",
    "    \n",
    "    ################################\n",
    "    #### 커맨드 인자 파싱   \n",
    "    #################################        \n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--base_output_dir', type=str, default=\"/opt/ml/processing/output\")\n",
    "    parser.add_argument('--base_preproc_input_dir', type=str, default=\"/opt/ml/processing/input\")   \n",
    "    parser.add_argument('--split_rate', type=float, default=0.1)       \n",
    "    parser.add_argument('--label_column', type=str, default=\"fraud\")       \n",
    "    # parse arguments\n",
    "    args = parser.parse_args()     \n",
    "    \n",
    "    logger.info(\"######### Argument Info ####################################\")\n",
    "    logger.info(f\"args.base_output_dir: {args.base_output_dir}\")\n",
    "    logger.info(f\"args.base_preproc_input_dir: {args.base_preproc_input_dir}\")    \n",
    "    logger.info(f\"args.label_column: {args.label_column}\")        \n",
    "    logger.info(f\"args.split_rate: {args.split_rate}\")            \n",
    "\n",
    "    base_output_dir = args.base_output_dir\n",
    "    base_preproc_input_dir = args.base_preproc_input_dir\n",
    "    label_column = args.label_column    \n",
    "    split_rate = args.split_rate\n",
    "\n",
    "    #################################        \n",
    "    #### 두개의 파일(claim, customer) 을 로딩하여 policy_id 로 조인함  ########\n",
    "    #################################    \n",
    "    \n",
    "    logger.info(f\"\\n### Loading Claim Dataset\")\n",
    "    claim_df = get_dataframe(base_preproc_input_dir,file_name_prefix='claim' )        \n",
    "    \n",
    "    logger.info(f\"\\n### Loading Customer Dataset\")    \n",
    "    customer_df = get_dataframe(base_preproc_input_dir,file_name_prefix='customer' )            \n",
    "    \n",
    "    df = customer_df.join(claim_df, how='left')\n",
    "    logger.info(f\"### dataframe merged with customer and claim: {df.shape}\")\n",
    "\n",
    "\n",
    "    #################################    \n",
    "    #### 카테고리 피쳐를 원핫인코딩  \n",
    "    #################################    \n",
    "    \n",
    "    logger.info(f\"\\n ### Encoding: Category Features\")    \n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.values.tolist()    \n",
    "    #categorical_features = ['driver_relationship']    \n",
    "    logger.info(f\"categorical_features: {categorical_features}\")            \n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        sparse_threshold = 0, # dense format 으로 제공\n",
    "    )\n",
    "\n",
    "    X_pre_category = preprocess.fit_transform(df)\n",
    "    \n",
    "\n",
    "    # 원핫인코딩한 컬럼의 이름 로딩\n",
    "    # Ref: Sklearn Pipeline: Get feature names after OneHotEncode In ColumnTransformer,  https://stackoverflow.com/questions/54646709/sklearn-pipeline-get-feature-names-after-onehotencode-in-columntransformer\n",
    "    \n",
    "    processed_category_features = preprocess.transformers_[0][1].named_steps['onehot'].get_feature_names(categorical_features)\n",
    "    #logger.info(f\"processed_category_features: {processed_category_features}\")\n",
    "#    print(X_pre)\n",
    "    \n",
    "    ###############################\n",
    "    ### 숫자형 변수 전처리 \n",
    "    ###############################\n",
    "    \n",
    "    logger.info(f\"\\n ### Encoding: Numeric Features\")        \n",
    "    \n",
    "    float_cols = df.select_dtypes(include=['float64']).columns.values\n",
    "    int_cols = df.select_dtypes(include=['int64']).columns.values\n",
    "    numeric_features = np.concatenate((float_cols, int_cols), axis=0).tolist()\n",
    "    \n",
    "    logger.info(f\"int_cols: \\n{int_cols}\")    \n",
    "    logger.info(f\"float_cols: \\n{float_cols}\")        \n",
    "    #logger.info(f\"numeric_features: \\n{numeric_features}\")\n",
    "\n",
    "    # 따로 스케일링은 하지 않고, 미싱 값만 중간값을 취함\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "           # (\"scaler\", StandardScaler())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    numeric_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", numeric_transformer, numeric_features)\n",
    "        ],\n",
    "        sparse_threshold = 0,\n",
    "    )\n",
    "\n",
    "    X_pre_numeric = numeric_preprocessor.fit_transform(df)    \n",
    "\n",
    "    \n",
    "    ###############################\n",
    "    ### 전처리 결과 결합 ####\n",
    "    ###############################\n",
    "    \n",
    "    logger.info(f\"\\n ### Handle preprocess results\")            \n",
    "    \n",
    "    # 전처리 결과를 데이터 프레임으로 생성\n",
    "    category_df = pd.DataFrame(data=X_pre_category, columns=processed_category_features)\n",
    "    numeric_df = pd.DataFrame(data=X_pre_numeric, columns=numeric_features)    \n",
    "\n",
    "    full_df = pd.concat([numeric_df, category_df ], axis=1)\n",
    "    \n",
    "    # float 타입을 int 로 변경\n",
    "    full_df = convert_type(full_df, cols=int_cols, type_target='int')\n",
    "    full_df = convert_type(full_df, cols=processed_category_features, type_target='int')    \n",
    "    \n",
    "    # label_column을 맨 앞으로 이동 시킴\n",
    "    full_df = pd.concat([full_df[label_column], full_df.drop(columns=[label_column])], axis=1)\n",
    "    \n",
    "    ###############################    \n",
    "    # 훈련, 테스트 데이터 세트로 분리 및 저장\n",
    "    ###############################\n",
    "    \n",
    "    train_df, test_df = split_train_test(full_df, test_ratio=split_rate)    \n",
    "    train_df.to_csv(f\"{base_output_dir}/dataset/train.csv\", index=False)\n",
    "    test_df.to_csv(f\"{base_output_dir}/dataset/test.csv\", index=False)    \n",
    "\n",
    "    logger.info(f\"preprocessed train shape \\n {train_df.shape}\")        \n",
    "    logger.info(f\"preprocessed test shape \\n {test_df.shape}\")            \n",
    "\n",
    "    # logger.info(f\"preprocessed train path \\n {base_output_dir}/train/train.csv\")\n",
    "    logger.info(f\"\\n ### Final result for train dataset \")    \n",
    "    logger.info(f\"preprocessed train sample \\n {train_df.head(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "processing_instance_type = \"ml.m5.xlarge\"\n",
    "processing_instance_count = 1\n",
    "split_rate = 0.1\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version = framework_version,\n",
    "    instance_type = processing_instance_type,\n",
    "    instance_count = processing_instance_count,\n",
    "    base_job_name = \"sklearn-fraud-process\",\n",
    "    role = role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sklearn-fraud-process-2022-07-25-08-58-29-293\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-457597599702/autoglueon/raw', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-457597599702/sklearn-fraud-process-2022-07-25-08-58-29-293/input/code/preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'dataset', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-457597599702/sklearn-fraud-process-2022-07-25-08-58-29-293/output/dataset', 'LocalPath': '/opt/ml/processing/output/dataset', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".........................\u001b[34m######### Argument Info ####################################\u001b[0m\n",
      "\u001b[34margs.base_output_dir: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34margs.base_preproc_input_dir: /opt/ml/processing/input\u001b[0m\n",
      "\u001b[34margs.label_column: fraud\u001b[0m\n",
      "\u001b[34margs.split_rate: 0.1\u001b[0m\n",
      "\u001b[34m### Loading Claim Dataset\u001b[0m\n",
      "\u001b[34minput_files: \n",
      " ['/opt/ml/processing/input/claims.csv']\u001b[0m\n",
      "\u001b[34mdataframe shape \n",
      " (5000, 17)\u001b[0m\n",
      "\u001b[34mdataset sample \n",
      "           driver_relationship incident_type  ... incident_hour fraud\u001b[0m\n",
      "\u001b[34mpolicy_id                                    ...                    \u001b[0m\n",
      "\u001b[34m1                      Spouse     Collision  ...             8     0\u001b[0m\n",
      "\u001b[34m2                        Self     Collision  ...            11     0\u001b[0m\n",
      "\u001b[34m[2 rows x 17 columns]\u001b[0m\n",
      "\u001b[34m### Loading Customer Dataset\u001b[0m\n",
      "\u001b[34minput_files: \n",
      " ['/opt/ml/processing/input/customers.csv']\u001b[0m\n",
      "\u001b[34mdataframe shape \n",
      " (5000, 12)\u001b[0m\n",
      "\u001b[34mdataset sample \n",
      "            customer_age  months_as_customer  ...  customer_education  auto_year\u001b[0m\n",
      "\u001b[34mpolicy_id                                    ...                               \u001b[0m\n",
      "\u001b[34m1                    54                  94  ...           Associate       2006\u001b[0m\n",
      "\u001b[34m2                    41                 165  ...            Bachelor       2012\u001b[0m\n",
      "\u001b[34m[2 rows x 12 columns]\u001b[0m\n",
      "\u001b[34m### dataframe merged with customer and claim: (5000, 29)\n",
      " ### Encoding: Category Features\u001b[0m\n",
      "\u001b[34mcategorical_features: ['policy_state', 'policy_liability', 'customer_gender', 'customer_education', 'driver_relationship', 'incident_type', 'collision_type', 'incident_severity', 'authorities_contacted', 'police_report_available']\n",
      " ### Encoding: Numeric Features\u001b[0m\n",
      "\u001b[34mint_cols: \u001b[0m\n",
      "\u001b[34m['customer_age' 'months_as_customer' 'num_claims_past_year'\n",
      " 'num_insurers_past_5_years' 'policy_deductable' 'policy_annual_premium'\n",
      " 'customer_zip' 'auto_year' 'num_vehicles_involved' 'num_injuries'\n",
      " 'num_witnesses' 'injury_claim' 'incident_month' 'incident_day'\n",
      " 'incident_dow' 'incident_hour' 'fraud']\u001b[0m\n",
      "\u001b[34mfloat_cols: \u001b[0m\n",
      "\u001b[34m['vehicle_claim' 'total_claim_amount']\n",
      " ### Handle preprocess results\u001b[0m\n",
      "\u001b[34mpreprocessed train shape \n",
      " (4500, 59)\u001b[0m\n",
      "\u001b[34mpreprocessed test shape \n",
      " (500, 59)\n",
      " ### Final result for train dataset \u001b[0m\n",
      "\u001b[34mpreprocessed train sample \n",
      "    fraud  ...  police_report_available_Yes\u001b[0m\n",
      "\u001b[34m0      0  ...                            0\u001b[0m\n",
      "\u001b[34m1      0  ...                            1\u001b[0m\n",
      "\u001b[34m[2 rows x 59 columns]\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sklearn_processor.run(\n",
    "    code = \"src/preprocess.py\",\n",
    "    inputs = [ProcessingInput(source = s3_data_path, destination = \"/opt/ml/processing/input\")],\n",
    "    outputs = [ProcessingOutput(output_name = \"dataset\",\n",
    "                                source = \"/opt/ml/processing/output/dataset\")],\n",
    "    arguments = ['--split_rate', f\"{split_rate}\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-457597599702/sklearn-fraud-process-2022-07-25-08-58-29-293/output/dataset'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_processor.latest_job.outputs[0].destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.s3.S3Downloader.download(s3_uri = sklearn_processor.latest_job.outputs[0].destination,\n",
    "                                   local_path = '../data/preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>num_claims_past_year</th>\n",
       "      <th>num_insurers_past_5_years</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>customer_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>collision_type_missing</th>\n",
       "      <th>incident_severity_Major</th>\n",
       "      <th>incident_severity_Minor</th>\n",
       "      <th>incident_severity_Totaled</th>\n",
       "      <th>authorities_contacted_Ambulance</th>\n",
       "      <th>authorities_contacted_Fire</th>\n",
       "      <th>authorities_contacted_None</th>\n",
       "      <th>authorities_contacted_Police</th>\n",
       "      <th>police_report_available_No</th>\n",
       "      <th>police_report_available_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8913.668763</td>\n",
       "      <td>80513.668763</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>99207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19746.724395</td>\n",
       "      <td>26146.724395</td>\n",
       "      <td>41</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>2950</td>\n",
       "      <td>95632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11652.969918</td>\n",
       "      <td>22052.969918</td>\n",
       "      <td>57</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>93203</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11260.930936</td>\n",
       "      <td>115960.930936</td>\n",
       "      <td>39</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>85208</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>27987.704652</td>\n",
       "      <td>31387.704652</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>91792</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraud  vehicle_claim  total_claim_amount  customer_age  months_as_customer  \\\n",
       "0      0    8913.668763        80513.668763            54                  94   \n",
       "1      0   19746.724395        26146.724395            41                 165   \n",
       "2      0   11652.969918        22052.969918            57                 155   \n",
       "3      0   11260.930936       115960.930936            39                  80   \n",
       "4      0   27987.704652        31387.704652            39                  60   \n",
       "\n",
       "   num_claims_past_year  num_insurers_past_5_years  policy_deductable  \\\n",
       "0                     0                          1                750   \n",
       "1                     0                          1                750   \n",
       "2                     0                          1                750   \n",
       "3                     0                          1                750   \n",
       "4                     0                          1                750   \n",
       "\n",
       "   policy_annual_premium  customer_zip  ...  collision_type_missing  \\\n",
       "0                   3000         99207  ...                       0   \n",
       "1                   2950         95632  ...                       0   \n",
       "2                   3000         93203  ...                       0   \n",
       "3                   3000         85208  ...                       0   \n",
       "4                   3000         91792  ...                       0   \n",
       "\n",
       "   incident_severity_Major  incident_severity_Minor  \\\n",
       "0                        0                        1   \n",
       "1                        0                        0   \n",
       "2                        0                        1   \n",
       "3                        0                        1   \n",
       "4                        1                        0   \n",
       "\n",
       "   incident_severity_Totaled  authorities_contacted_Ambulance  \\\n",
       "0                          0                                0   \n",
       "1                          1                                0   \n",
       "2                          0                                0   \n",
       "3                          0                                0   \n",
       "4                          0                                0   \n",
       "\n",
       "   authorities_contacted_Fire  authorities_contacted_None  \\\n",
       "0                           0                           1   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           1   \n",
       "4                           0                           0   \n",
       "\n",
       "   authorities_contacted_Police  police_report_available_No  \\\n",
       "0                             0                           1   \n",
       "1                             1                           0   \n",
       "2                             1                           0   \n",
       "3                             0                           1   \n",
       "4                             1                           1   \n",
       "\n",
       "   police_report_available_Yes  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            0  \n",
       "4                            0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_path = '../data/preprocessed/train.csv'\n",
    "preprocessed_train_df = pd.read_csv(preprocessed_train_path)\n",
    "preprocessed_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 빌딩 파이프라인의 스텝 생성\n",
    "## 모델 빌딩 파이프라인의 파라미터 정의\n",
    "파이프라인에서 사용 할 파라미터를 정의합니다. 파이프라인을 실행할 때 파라미터를 이용하여 실행 조건을 커스터마이징 할 수 있습니다.\n",
    "지원하는 파라미터 타입은 다음과 같습니다.\n",
    "\n",
    "* `ParameterString` - 파이썬 타입에서 `str` \n",
    "* `ParameterInteger` - 파이썬 타입에서 `int` \n",
    "* `ParameterFloat` - 파이썬 타입에서 `float` \n",
    "\n",
    "디폴트 값을 지정할 수 있으며, 파이프라인 실행 시 재지정 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=s3_data_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 스텝 프로세서 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.100.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "processing_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-fraud-process\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 스텝 정의\n",
    "Processing Step에서는 다음과 같은 인자들을 지정합니다.\n",
    "* name: 스텝 명\n",
    "* processor: 전처리 프로세서\n",
    "* inputs: 입력 데이터 S3 경로\n",
    "* outputs: 처리결과가 저장 될 Docker 안의 경로\n",
    "* job arguments: 사용자 정의 인자\n",
    "* code: 전처리 코드 경로\n",
    "\n",
    "보다 자세한 내용은 링크를 확인하세요\n",
    "[처리 단계, Processing Step](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "    \n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"Fraud-Preprocessing\",\n",
    "    processor=sklearn_processor,\n",
    "    code= \"src/preprocess.py\",\n",
    "    inputs = [ProcessingInput(source = s3_data_path, destination = \"/opt/ml/processing/input\")],\n",
    "    outputs = [ProcessingOutput(output_name = \"dataset\",\n",
    "                                source = \"/opt/ml/processing/output/dataset\")],\n",
    "    job_arguments = ['--split_rate', f\"{split_rate}\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이프라인 정의 및 실행\n",
    "생성한 단계들을 하나의 파이프라인으로 조합하고 실행할 수 있습니다.\n",
    "파이프라인은 name, parapeters, steps 인자가 필수로 필요합니다. \n",
    "여기서 파이프라인의 name은 Account와 Region에 대해 유일해야 합니다.\n",
    "\n",
    "주의사항:\n",
    "- 정의에 사용한 모든 파라미터가 존재해야 합니다.\n",
    "- 파이프라인으로 전달된 단계(step)들은 실행순서와는 무관합니다. SageMaker Pipeline은 단계가 실행되고 완료될 수 있도록 의존관계를를 해석합니다.\n",
    "- [알림] 정의한 stpes 이 복수개이면 복수개를 기술합니다. 만약에 step 간에 의존성이 있으면, 명시적으로 기술하지 않아도 같이 실행 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = pipeline_prefix\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type, \n",
    "        processing_instance_count,\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_process],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'ProcessingInstanceCount',\n",
       "   'Type': 'Integer',\n",
       "   'DefaultValue': 1},\n",
       "  {'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-us-east-1-238312515155/sm-autoglueon-pipeline-base/data'}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'Fraud-Preprocessing',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "     'ContainerArguments': ['--split_rate', '0.1'],\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/preprocess.py']},\n",
       "    'RoleArn': 'arn:aws:iam::238312515155:role/service-role/AmazonSageMaker-ExecutionRole-20220512T204782',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/sm-autoglueon-pipeline-base/data',\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/Fraud-Preprocessing-4726a17e84cc4cba842a7a78306a5861/input/code/preprocess.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'dataset',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/Fraud-Preprocessing-4726a17e84cc4cba842a7a78306a5861/output/dataset',\n",
       "        'LocalPath': '/opt/ml/processing/output/dataset',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이프라인 정의를 등록하고 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:238312515155:pipeline/sm-autoglueon-pipeline-base',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:238312515155:pipeline/sm-autoglueon-pipeline-base/execution/5ovkwrorpqeb',\n",
       " 'PipelineExecutionDisplayName': 'execution-1658556036042',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2022, 7, 23, 6, 0, 35, 935000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 7, 23, 6, 0, 35, 935000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:238312515155:user-profile/d-no5jmo24zdtn/shimdx-c39',\n",
       "  'UserProfileName': 'shimdx-c39',\n",
       "  'DomainId': 'd-no5jmo24zdtn'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:238312515155:user-profile/d-no5jmo24zdtn/shimdx-c39',\n",
       "  'UserProfileName': 'shimdx-c39',\n",
       "  'DomainId': 'd-no5jmo24zdtn'},\n",
       " 'ResponseMetadata': {'RequestId': '046cf723-e952-44e1-9da8-eae91b6e8638',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '046cf723-e952-44e1-9da8-eae91b6e8638',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '733',\n",
       "   'date': 'Sat, 23 Jul 2022 06:00:35 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'Fraud-Preprocessing',\n",
       "  'StartTime': datetime.datetime(2022, 7, 23, 6, 0, 37, 28000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 7, 23, 6, 5, 5, 414000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:238312515155:processing-job/pipelines-5ovkwrorpqeb-fraud-preprocessing-bofkyfacai'}}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
