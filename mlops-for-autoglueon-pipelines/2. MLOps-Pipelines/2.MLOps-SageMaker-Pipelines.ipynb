{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 2] SageMaker Pipelines 사용하기\n",
    "이 노트북에서는 아래와 같은 작업을 수행합니다.\n",
    "- 데이터 준비\n",
    "- Pipeline 정의\n",
    "- 데이터 전처리: Processing Step 이용 \n",
    "- Autoglueon을 이용한 학습: Training Step 이용\n",
    "- Hyper Parameter Optimizer를 이용한 최적화: Tuning Step 이용\n",
    "- 검증데이터 추론: Processing Step 이용\n",
    "- 학습결과 Evaluation하기: Processing Step 이용\n",
    "- Condition 확인하여 모델 등록하기: Condition Step 이용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# role = sagemaker.get_execution_role()\n",
    "# sess = boto3.Session()\n",
    "# region = sess.region_name\n",
    "# account = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "# bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_prefix = 'sm-autoglueon-pipeline-base'\n",
    "s3_data_path =f's3://{bucket}/{pipeline_prefix}/data'\n",
    "\n",
    "nb_dataset_path = '../data/raw'\n",
    "claims_data_path = f'{nb_dataset_path}/claims.csv'\n",
    "customers_data_path = f'{nb_dataset_path}/customers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_data_path:  ../data/raw/claims.csv\n",
      "customer_data_path:  ../data/raw/customers.csv\n",
      "s3_data_path:  s3://sagemaker-us-east-1-238312515155/sm-autoglueon-pipeline-base/data\n"
     ]
    }
   ],
   "source": [
    "print(\"claim_data_path: \", claims_data_path)\n",
    "print(\"customer_data_path: \", customers_data_path)\n",
    "print(\"s3_data_path: \", s3_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claims data path in S3:  s3://sagemaker-us-east-1-238312515155/sm-autoglueon-pipeline-base/data/claims.csv\n",
      "customers data path in S3:  s3://sagemaker-us-east-1-238312515155/sm-autoglueon-pipeline-base/data/customers.csv\n"
     ]
    }
   ],
   "source": [
    "s3_claims_data_path = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path = claims_data_path, \n",
    "    desired_s3_uri = s3_data_path\n",
    ")\n",
    "print(\"claims data path in S3: \", s3_claims_data_path)\n",
    "\n",
    "s3_customers_data_path = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path = customers_data_path, \n",
    "    desired_s3_uri = s3_data_path\n",
    ")\n",
    "print(\"customers data path in S3: \", s3_customers_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 전처리 스텝 개발"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from IPython.display import display as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_id</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>num_claims_past_year</th>\n",
       "      <th>num_insurers_past_5_years</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>policy_liability</th>\n",
       "      <th>customer_zip</th>\n",
       "      <th>customer_gender</th>\n",
       "      <th>customer_education</th>\n",
       "      <th>auto_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>25/50</td>\n",
       "      <td>99207</td>\n",
       "      <td>Unkown</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>2950</td>\n",
       "      <td>15/30</td>\n",
       "      <td>95632</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>15/30</td>\n",
       "      <td>93203</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AZ</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>30/60</td>\n",
       "      <td>85208</td>\n",
       "      <td>Female</td>\n",
       "      <td>Advanced Degree</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>750</td>\n",
       "      <td>3000</td>\n",
       "      <td>15/30</td>\n",
       "      <td>91792</td>\n",
       "      <td>Female</td>\n",
       "      <td>High School</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policy_id  customer_age  months_as_customer  num_claims_past_year  \\\n",
       "0          1            54                  94                     0   \n",
       "1          2            41                 165                     0   \n",
       "2          3            57                 155                     0   \n",
       "3          4            39                  80                     0   \n",
       "4          5            39                  60                     0   \n",
       "\n",
       "   num_insurers_past_5_years policy_state  policy_deductable  \\\n",
       "0                          1           WA                750   \n",
       "1                          1           CA                750   \n",
       "2                          1           CA                750   \n",
       "3                          1           AZ                750   \n",
       "4                          1           CA                750   \n",
       "\n",
       "   policy_annual_premium policy_liability  customer_zip customer_gender  \\\n",
       "0                   3000            25/50         99207          Unkown   \n",
       "1                   2950            15/30         95632            Male   \n",
       "2                   3000            15/30         93203          Female   \n",
       "3                   3000            30/60         85208          Female   \n",
       "4                   3000            15/30         91792          Female   \n",
       "\n",
       "  customer_education  auto_year  \n",
       "0          Associate       2006  \n",
       "1           Bachelor       2012  \n",
       "2           Bachelor       2017  \n",
       "3    Advanced Degree       2020  \n",
       "4        High School       2018  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers = pd.read_csv(customers_data_path)\n",
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_id</th>\n",
       "      <th>driver_relationship</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>collision_type</th>\n",
       "      <th>incident_severity</th>\n",
       "      <th>authorities_contacted</th>\n",
       "      <th>num_vehicles_involved</th>\n",
       "      <th>num_injuries</th>\n",
       "      <th>num_witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>incident_month</th>\n",
       "      <th>incident_day</th>\n",
       "      <th>incident_dow</th>\n",
       "      <th>incident_hour</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Front</td>\n",
       "      <td>Minor</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>71600</td>\n",
       "      <td>8913.668763</td>\n",
       "      <td>80513.668763</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Rear</td>\n",
       "      <td>Totaled</td>\n",
       "      <td>Police</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6400</td>\n",
       "      <td>19746.724395</td>\n",
       "      <td>26146.724395</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Front</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Police</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10400</td>\n",
       "      <td>11652.969918</td>\n",
       "      <td>22052.969918</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Child</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Side</td>\n",
       "      <td>Minor</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>104700</td>\n",
       "      <td>11260.930936</td>\n",
       "      <td>115960.930936</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Self</td>\n",
       "      <td>Collision</td>\n",
       "      <td>Side</td>\n",
       "      <td>Major</td>\n",
       "      <td>Police</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>3400</td>\n",
       "      <td>27987.704652</td>\n",
       "      <td>31387.704652</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policy_id driver_relationship incident_type collision_type  \\\n",
       "0          1              Spouse     Collision          Front   \n",
       "1          2                Self     Collision           Rear   \n",
       "2          3                Self     Collision          Front   \n",
       "3          4               Child     Collision           Side   \n",
       "4          5                Self     Collision           Side   \n",
       "\n",
       "  incident_severity authorities_contacted  num_vehicles_involved  \\\n",
       "0             Minor                  None                      2   \n",
       "1           Totaled                Police                      3   \n",
       "2             Minor                Police                      2   \n",
       "3             Minor                  None                      2   \n",
       "4             Major                Police                      2   \n",
       "\n",
       "   num_injuries  num_witnesses police_report_available  injury_claim  \\\n",
       "0             0              0                      No         71600   \n",
       "1             4              0                     Yes          6400   \n",
       "2             0              1                     Yes         10400   \n",
       "3             0              0                      No        104700   \n",
       "4             1              0                      No          3400   \n",
       "\n",
       "   vehicle_claim  total_claim_amount  incident_month  incident_day  \\\n",
       "0    8913.668763        80513.668763               3            17   \n",
       "1   19746.724395        26146.724395              12            11   \n",
       "2   11652.969918        22052.969918              12            24   \n",
       "3   11260.930936       115960.930936              12            23   \n",
       "4   27987.704652        31387.704652               5             8   \n",
       "\n",
       "   incident_dow  incident_hour  fraud  \n",
       "0             6              8      0  \n",
       "1             2             11      0  \n",
       "2             1             14      0  \n",
       "3             0             19      0  \n",
       "4             2              8      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claims = pd.read_csv(claims_data_path)\n",
    "df_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/preprocess.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import subprocess, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import logging\n",
    "import logging.handlers\n",
    "\n",
    "def _get_logger():\n",
    "    '''\n",
    "    로깅을 위해 파이썬 로거를 사용\n",
    "    # https://stackoverflow.com/questions/17745914/python-logging-module-is-printing-lines-multiple-times\n",
    "    '''\n",
    "    loglevel = logging.DEBUG\n",
    "    l = logging.getLogger(__name__)\n",
    "    if not l.hasHandlers():\n",
    "        l.setLevel(loglevel)\n",
    "        logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))        \n",
    "        l.handler_set = True\n",
    "    return l  \n",
    "\n",
    "logger = _get_logger()\n",
    "\n",
    "\n",
    "def split_train_test(df, test_ratio=0.1):\n",
    "    '''\n",
    "    두 개의 데이터 세트로 분리\n",
    "    '''\n",
    "    total_rows = df.shape[0]\n",
    "    train_end = int(total_rows * (1 - test_ratio))\n",
    "    \n",
    "    train_df = df[0:train_end]\n",
    "    test_df = df[train_end:]\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def get_dataframe(base_preproc_input_dir, file_name_prefix ):    \n",
    "    '''\n",
    "    파일 이름이 들어가 있는 csv 파일을 모두 저장하여 데이터 프레임을 리턴\n",
    "    '''\n",
    "    \n",
    "    input_files = glob('{}/{}*.csv'.format(base_preproc_input_dir, file_name_prefix))\n",
    "    #claim_input_files = glob('{}/dataset*.csv'.format(base_preproc_input_dir))    \n",
    "    logger.info(f\"input_files: \\n {input_files}\")    \n",
    "    \n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(base_preproc_input_dir, \"train\"))\n",
    "        \n",
    "    raw_data = [ pd.read_csv(file, index_col=0) for file in input_files ]\n",
    "    df = pd.concat(raw_data)\n",
    "   \n",
    "    logger.info(f\"dataframe shape \\n {df.shape}\")    \n",
    "    logger.info(f\"dataset sample \\n {df.head(2)}\")        \n",
    "    #logger.info(f\"df columns \\n {df.columns}\")    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_type(raw, cols, type_target):\n",
    "    '''\n",
    "    해당 데이터 타입으로 변경\n",
    "    '''\n",
    "    df = raw.copy()\n",
    "    \n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(type_target)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "if __name__ =='__main__':\n",
    "    \n",
    "    ################################\n",
    "    #### 커맨드 인자 파싱   \n",
    "    #################################        \n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--base_output_dir', type=str, default=\"/opt/ml/processing/output\")\n",
    "    parser.add_argument('--base_preproc_input_dir', type=str, default=\"/opt/ml/processing/input\")   \n",
    "    parser.add_argument('--split_rate', type=float, default=0.1)       \n",
    "    parser.add_argument('--label_column', type=str, default=\"fraud\")       \n",
    "    # parse arguments\n",
    "    args = parser.parse_args()     \n",
    "    \n",
    "    logger.info(\"######### Argument Info ####################################\")\n",
    "    logger.info(f\"args.base_output_dir: {args.base_output_dir}\")\n",
    "    logger.info(f\"args.base_preproc_input_dir: {args.base_preproc_input_dir}\")    \n",
    "    logger.info(f\"args.label_column: {args.label_column}\")        \n",
    "    logger.info(f\"args.split_rate: {args.split_rate}\")            \n",
    "\n",
    "    base_output_dir = args.base_output_dir\n",
    "    base_preproc_input_dir = args.base_preproc_input_dir\n",
    "    label_column = args.label_column    \n",
    "    split_rate = args.split_rate\n",
    "\n",
    "    #################################        \n",
    "    #### 두개의 파일(claim, customer) 을 로딩하여 policy_id 로 조인함  ########\n",
    "    #################################    \n",
    "    \n",
    "    logger.info(f\"\\n### Loading Claim Dataset\")\n",
    "    claim_df = get_dataframe(base_preproc_input_dir,file_name_prefix='claim' )        \n",
    "    \n",
    "    logger.info(f\"\\n### Loading Customer Dataset\")    \n",
    "    customer_df = get_dataframe(base_preproc_input_dir,file_name_prefix='customer' )            \n",
    "    \n",
    "    df = customer_df.join(claim_df, how='left')\n",
    "    logger.info(f\"### dataframe merged with customer and claim: {df.shape}\")\n",
    "\n",
    "\n",
    "    #################################    \n",
    "    #### 카테고리 피쳐를 원핫인코딩  \n",
    "    #################################    \n",
    "    \n",
    "    logger.info(f\"\\n ### Encoding: Category Features\")    \n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.values.tolist()    \n",
    "    #categorical_features = ['driver_relationship']    \n",
    "    logger.info(f\"categorical_features: {categorical_features}\")            \n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        sparse_threshold = 0, # dense format 으로 제공\n",
    "    )\n",
    "\n",
    "    X_pre_category = preprocess.fit_transform(df)\n",
    "    \n",
    "\n",
    "    # 원핫인코딩한 컬럼의 이름 로딩\n",
    "    # Ref: Sklearn Pipeline: Get feature names after OneHotEncode In ColumnTransformer,  https://stackoverflow.com/questions/54646709/sklearn-pipeline-get-feature-names-after-onehotencode-in-columntransformer\n",
    "    \n",
    "    processed_category_features = preprocess.transformers_[0][1].named_steps['onehot'].get_feature_names(categorical_features)\n",
    "    #logger.info(f\"processed_category_features: {processed_category_features}\")\n",
    "#    print(X_pre)\n",
    "    \n",
    "    ###############################\n",
    "    ### 숫자형 변수 전처리 \n",
    "    ###############################\n",
    "    \n",
    "    logger.info(f\"\\n ### Encoding: Numeric Features\")        \n",
    "    \n",
    "    float_cols = df.select_dtypes(include=['float64']).columns.values\n",
    "    int_cols = df.select_dtypes(include=['int64']).columns.values\n",
    "    numeric_features = np.concatenate((float_cols, int_cols), axis=0).tolist()\n",
    "    \n",
    "    logger.info(f\"int_cols: \\n{int_cols}\")    \n",
    "    logger.info(f\"float_cols: \\n{float_cols}\")        \n",
    "    #logger.info(f\"numeric_features: \\n{numeric_features}\")\n",
    "\n",
    "    # 따로 스케일링은 하지 않고, 미싱 값만 중간값을 취함\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "           # (\"scaler\", StandardScaler())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    numeric_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", numeric_transformer, numeric_features)\n",
    "        ],\n",
    "        sparse_threshold = 0,\n",
    "    )\n",
    "\n",
    "    X_pre_numeric = numeric_preprocessor.fit_transform(df)    \n",
    "\n",
    "    \n",
    "    ###############################\n",
    "    ### 전처리 결과 결합 ####\n",
    "    ###############################\n",
    "    \n",
    "    logger.info(f\"\\n ### Handle preprocess results\")            \n",
    "    \n",
    "    # 전처리 결과를 데이터 프레임으로 생성\n",
    "    category_df = pd.DataFrame(data=X_pre_category, columns=processed_category_features)\n",
    "    numeric_df = pd.DataFrame(data=X_pre_numeric, columns=numeric_features)    \n",
    "\n",
    "    full_df = pd.concat([numeric_df, category_df ], axis=1)\n",
    "    \n",
    "    # float 타입을 int 로 변경\n",
    "    full_df = convert_type(full_df, cols=int_cols, type_target='int')\n",
    "    full_df = convert_type(full_df, cols=processed_category_features, type_target='int')    \n",
    "    \n",
    "    # label_column을 맨 앞으로 이동 시킴\n",
    "    full_df = pd.concat([full_df[label_column], full_df.drop(columns=[label_column])], axis=1)\n",
    "    \n",
    "    ###############################    \n",
    "    # 훈련, 테스트 데이터 세트로 분리 및 저장\n",
    "    ###############################\n",
    "    \n",
    "    train_df, test_df = split_train_test(full_df, test_ratio=split_rate)    \n",
    "    train_df.to_csv(f\"{base_output_dir}/train/train.csv\", index=False)\n",
    "    test_df.to_csv(f\"{base_output_dir}/test/test.csv\", index=False)    \n",
    "\n",
    "    logger.info(f\"preprocessed train shape \\n {train_df.shape}\")        \n",
    "    logger.info(f\"preprocessed test shape \\n {test_df.shape}\")            \n",
    "\n",
    "    # logger.info(f\"preprocessed train path \\n {base_output_dir}/train/train.csv\")\n",
    "    logger.info(f\"\\n ### Final result for train dataset \")    \n",
    "    logger.info(f\"preprocessed train sample \\n {train_df.head(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sklearn-fraud-process-2022-07-21-07-37-25-130\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/sm-autoglueon-pipeline-base/data', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/sklearn-fraud-process-2022-07-21-07-37-25-130/input/code/preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/sklearn-fraud-process-2022-07-21-07-37-25-130/output/train', 'LocalPath': '/opt/ml/processing/output/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-238312515155/sklearn-fraud-process-2022-07-21-07-37-25-130/output/test', 'LocalPath': '/opt/ml/processing/output/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      "............................\u001b[34m######### Argument Info ####################################\u001b[0m\n",
      "\u001b[34margs.base_output_dir: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34margs.base_preproc_input_dir: /opt/ml/processing/input\u001b[0m\n",
      "\u001b[34margs.label_column: fraud\u001b[0m\n",
      "\u001b[34margs.split_rate: 0.1\u001b[0m\n",
      "\u001b[34m### Loading Claim Dataset\u001b[0m\n",
      "\u001b[34minput_files: \n",
      " ['/opt/ml/processing/input/claims.csv']\u001b[0m\n",
      "\u001b[34mdataframe shape \n",
      " (5000, 17)\u001b[0m\n",
      "\u001b[34mdataset sample \n",
      "           driver_relationship incident_type  ... incident_hour fraud\u001b[0m\n",
      "\u001b[34mpolicy_id                                    ...                    \u001b[0m\n",
      "\u001b[34m1                      Spouse     Collision  ...             8     0\u001b[0m\n",
      "\u001b[34m2                        Self     Collision  ...            11     0\u001b[0m\n",
      "\u001b[34m[2 rows x 17 columns]\u001b[0m\n",
      "\u001b[34m### Loading Customer Dataset\u001b[0m\n",
      "\u001b[34minput_files: \n",
      " ['/opt/ml/processing/input/customers.csv']\u001b[0m\n",
      "\u001b[34mdataframe shape \n",
      " (5000, 12)\u001b[0m\n",
      "\u001b[34mdataset sample \n",
      "            customer_age  months_as_customer  ...  customer_education  auto_year\u001b[0m\n",
      "\u001b[34mpolicy_id                                    ...                               \u001b[0m\n",
      "\u001b[34m1                    54                  94  ...           Associate       2006\u001b[0m\n",
      "\u001b[34m2                    41                 165  ...            Bachelor       2012\u001b[0m\n",
      "\u001b[34m[2 rows x 12 columns]\u001b[0m\n",
      "\u001b[34m### dataframe merged with customer and claim: (5000, 29)\n",
      " ### Encoding: Category Features\u001b[0m\n",
      "\u001b[34mcategorical_features: ['policy_state', 'policy_liability', 'customer_gender', 'customer_education', 'driver_relationship', 'incident_type', 'collision_type', 'incident_severity', 'authorities_contacted', 'police_report_available']\n",
      " ### Encoding: Numeric Features\u001b[0m\n",
      "\u001b[34mint_cols: \u001b[0m\n",
      "\u001b[34m['customer_age' 'months_as_customer' 'num_claims_past_year'\n",
      " 'num_insurers_past_5_years' 'policy_deductable' 'policy_annual_premium'\n",
      " 'customer_zip' 'auto_year' 'num_vehicles_involved' 'num_injuries'\n",
      " 'num_witnesses' 'injury_claim' 'incident_month' 'incident_day'\n",
      " 'incident_dow' 'incident_hour' 'fraud']\u001b[0m\n",
      "\u001b[34mfloat_cols: \u001b[0m\n",
      "\u001b[34m['vehicle_claim' 'total_claim_amount']\n",
      " ### Handle preprocess results\u001b[0m\n",
      "\u001b[34mpreprocessed train shape \n",
      " (4500, 59)\u001b[0m\n",
      "\u001b[34mpreprocessed test shape \n",
      " (500, 59)\n",
      " ### Final result for train dataset \u001b[0m\n",
      "\u001b[34mpreprocessed train sample \n",
      "    fraud  ...  police_report_available_Yes\u001b[0m\n",
      "\u001b[34m0      0  ...                            0\u001b[0m\n",
      "\u001b[34m1      0  ...                            1\u001b[0m\n",
      "\u001b[34m[2 rows x 59 columns]\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "framework_version = \"0.23-1\"\n",
    "processing_instance_type = \"ml.m5.xlarge\"\n",
    "processing_instance_count = 1\n",
    "split_rate = 0.1\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version = framework_version,\n",
    "    instance_type = processing_instance_type,\n",
    "    instance_count = processing_instance_count,\n",
    "    base_job_name = \"sklearn-fraud-process\",\n",
    "    role = role,\n",
    ")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code = \"src/preprocess.py\",\n",
    "    inputs = [ProcessingInput(source = s3_data_path, destination = \"/opt/ml/processing/input\")],\n",
    "    outputs = [ProcessingOutput(output_name = \"train\",\n",
    "                                source = \"/opt/ml/processing/output/train\"),\n",
    "               ProcessingOutput(output_name = \"test\",\n",
    "                                source = \"/opt/ml/processing/output/test\")],\n",
    "    arguments = ['--split_rate', f\"{split_rate}\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
